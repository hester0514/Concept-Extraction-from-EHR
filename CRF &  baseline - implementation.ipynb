{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "421a58e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "from future.utils import iteritems\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.feature_extraction.text import HashingVectorizer\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.linear_model import PassiveAggressiveClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import classification_report\n",
    "from subprocess import check_output\n",
    "\n",
    "import sklearn_crfsuite\n",
    "from sklearn_crfsuite import scorers\n",
    "from sklearn_crfsuite import metrics\n",
    "from collections import Counter\n",
    "import sklearn_crfsuite\n",
    "\n",
    "import keras\n",
    "from keras.models import Model, Input, Sequential\n",
    "from keras.layers import LSTM, Embedding, Dense, TimeDistributed, Dropout, Bidirectional\n",
    "from keras_contrib.layers import CRF\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping \n",
    "import string\n",
    "\n",
    "import tensorflow\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4250d07c",
   "metadata": {},
   "outputs": [],
   "source": [
    "beth = pd.read_csv('train_data/conll.txt', sep=\" \", \n",
    "                         names = [\"word\", \"POS_tag\",\"chunk_tag\", \"NER_tag\", \"Sentence #\"],\n",
    "                         index_col = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dff7230d",
   "metadata": {},
   "outputs": [],
   "source": [
    "beth = beth.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "85e04467",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NER_tag\n",
       "O            111655\n",
       "problem       16774\n",
       "test           8259\n",
       "treatment      8662\n",
       "Name: word, dtype: int64"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "beth.groupby('NER_tag')['word'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "559c059b",
   "metadata": {},
   "outputs": [],
   "source": [
    "punc = [\"'\", \"!\", \"(\", \")\", \"-\", \"[\", \"]\", \"{\", \"}\", \",\", \":\", \";\", \"@\", \"<\", \">\"\n",
    "        \"#\", \"?\", \"~\", \"_\", \"&\", \"*\", \"/\",\"^\"]\n",
    "beth_train = beth_train[~beth_train['word'].isin(punc)]\n",
    "beth_train = beth_train.dropna()\n",
    "beth_test = beth_test[~beth_test['word'].isin(punc)]\n",
    "beth_test = beth_test.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ca9a712d",
   "metadata": {},
   "outputs": [],
   "source": [
    "beth_X = beth.drop('NER_tag', axis=1)\n",
    "v = DictVectorizer(sparse=False)\n",
    "beth_X = v.fit_transform(beth_X.to_dict('records'))\n",
    "beth_y = beth.NER_tag.values\n",
    "\n",
    "classes = np.unique(beth_y)\n",
    "classes = classes.tolist()\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    beth_X, beth_y, test_size = 0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7ef1590e",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_classes = classes.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87d67466",
   "metadata": {},
   "source": [
    "#### Baseline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dfc68dc",
   "metadata": {},
   "source": [
    "#### 1.1 Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "75bd3746",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=0.01)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb = MultinomialNB(alpha=0.01)\n",
    "nb.partial_fit(X_train, y_train, classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e9f38342",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           O       0.96      0.93      0.94     22395\n",
      "     problem       0.73      0.77      0.75      3398\n",
      "        test       0.70      0.81      0.75      1558\n",
      "   treatment       0.67      0.76      0.71      1719\n",
      "\n",
      "    accuracy                           0.89     29070\n",
      "   macro avg       0.76      0.82      0.79     29070\n",
      "weighted avg       0.90      0.89      0.90     29070\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_pred=nb.predict(X_test), y_true=y_test, labels = new_classes))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c194873",
   "metadata": {},
   "source": [
    "#### 1.2 Linear classifiers with SGD training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3672e5d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SGDClassifier()"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sgd = SGDClassifier()\n",
    "sgd.partial_fit(X_train, y_train, classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1e49c500",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           O       0.86      0.99      0.92     22395\n",
      "     problem       0.82      0.46      0.59      3398\n",
      "        test       0.82      0.46      0.59      1558\n",
      "   treatment       0.86      0.27      0.41      1719\n",
      "\n",
      "    accuracy                           0.86     29070\n",
      "   macro avg       0.84      0.54      0.63     29070\n",
      "weighted avg       0.85      0.86      0.83     29070\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_pred=sgd.predict(X_test), y_true=y_test, labels=new_classes))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97aa08f9",
   "metadata": {},
   "source": [
    "#### CRF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fa3b43a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SentenceGetter(object):\n",
    "    \n",
    "    def __init__(self, data):\n",
    "        self.n_sent = 1\n",
    "        self.data = data\n",
    "        self.empty = False\n",
    "        agg_func = lambda s: [(w, p, t) for w, p, t in zip(s['word'].values.tolist(), \n",
    "                                                           s['POS_tag'].values.tolist(), \n",
    "                                                           s['NER_tag'].values.tolist())]\n",
    "        self.grouped = self.data.groupby('Sentence #').apply(agg_func)\n",
    "        self.sentences = [s for s in self.grouped]\n",
    "        \n",
    "    def get_next(self):\n",
    "        try: \n",
    "            s = self.grouped['Sentence:{}'.format(self.n_sent)]\n",
    "            self.n_sent += 1\n",
    "            return s \n",
    "        except:\n",
    "            return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "42354f15",
   "metadata": {},
   "outputs": [],
   "source": [
    "getter = SentenceGetter(beth)\n",
    "sentences = getter.sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e832d98c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def word2features(sent, i):\n",
    "    word = sent[i][0]\n",
    "    postag = sent[i][1]\n",
    "    \n",
    "    features = {\n",
    "        'bias': 1.0, \n",
    "        'word.lower()': word.lower(), \n",
    "        'word[:4]': word[:4],\n",
    "        'word[:3]': word[:3],\n",
    "        'word[:2]': word[:2],\n",
    "        'word[-4:]': word[-4:],\n",
    "        'word[-3:]': word[-3:],\n",
    "        'word[-2:]': word[-2:],\n",
    "        'word.isupper()': word.isupper(),\n",
    "        'word.istitle()': word.istitle(),\n",
    "        'word.isdigit()': word.isdigit(),\n",
    "        'word.ispunctuation': (word in string.punctuation),\n",
    "        'postag': postag,\n",
    "        'postag[:2]': postag[:2]\n",
    "    }\n",
    "    if i > 0:\n",
    "        word1 = sent[i-1][0]\n",
    "        postag1 = sent[i-1][1]\n",
    "        features.update({\n",
    "            '-1:word.lower()': word1.lower(),\n",
    "            '-1:word.istitle()': word1.istitle(),\n",
    "            '-1:word.isupper()': word1.isupper(),\n",
    "            '-1:word[:3]': word1[:3],\n",
    "            '-1:word[:2]': word1[:2],\n",
    "            '-1:word[-3:]': word1[-3:],\n",
    "            '-1:word[-2:]': word1[-2:],\n",
    "            '-1:postag': postag1,\n",
    "            '-1:postag[:2]': postag1[:2],\n",
    "            '-1:word.ispunctuation': (word1 in string.punctuation)\n",
    "        })\n",
    "    else:\n",
    "        features['BOS'] = True\n",
    "    if i < len(sent)-1:\n",
    "        word1 = sent[i+1][0]\n",
    "        postag1 = sent[i+1][1]\n",
    "        features.update({\n",
    "            '+1:word.lower()': word1.lower(),\n",
    "            '+1:word.istitle()': word1.istitle(),\n",
    "            '+1:word.isupper()': word1.isupper(),\n",
    "            '+1:word[:3]': word1[:3],\n",
    "            '+1:word[:2]': word1[:2],\n",
    "            '+1:word[-3:]': word1[-3:],\n",
    "            '+1:word[-2:]': word1[-2:],\n",
    "            '+1:postag': postag1,\n",
    "            '+1:postag[:2]': postag1[:2],\n",
    "            '+1:word.ispunctuation': (word1 in string.punctuation)\n",
    "        })\n",
    "    else:\n",
    "        features['EOS'] = True\n",
    "        \n",
    "    if i < len(sent) - 2:\n",
    "        word2 = sent[i+2][0]\n",
    "        postag2 = sent[i+2][1]\n",
    "        features.update({\n",
    "            '+2:word': word2,\n",
    "            '+2:len(word)': len(word2),\n",
    "            '+2:word.lower()': word1.lower(),\n",
    "            '+2:word.istitle()': word1.istitle(),\n",
    "            '+2:word.isupper()': word1.isupper(),\n",
    "            '+2:word[:3]': word2[:3],\n",
    "            '+2:word[:2]': word2[:2],\n",
    "            '+2:word[-3:]': word2[-3:],\n",
    "            '+2:word[-2:]': word2[-2:],\n",
    "            '+2:word.isdigit()': word2.isdigit(),\n",
    "            '+2:word.ispunctuation': (word2 in string.punctuation),\n",
    "            '+2:postag': postag2,\n",
    "            '+2:postag[:2]': postag2[:2],\n",
    "    })\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "288a6332",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sent2features(sent):\n",
    "    return [word2features(sent, i) for i in range(len(sent))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "72656d26",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sent2labels(sent):\n",
    "    return [label for token, postag, label in sent]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8d108bd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sent2tokens(sent):\n",
    "    return [token for token, postag, label in sent]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5c8c6314",
   "metadata": {},
   "outputs": [],
   "source": [
    "beth_X = [sent2features(s) for s in sentences]\n",
    "beth_y = [sent2labels(s) for s in sentences]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "958ce462",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    beth_X, beth_y, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1fddbefb",
   "metadata": {},
   "outputs": [],
   "source": [
    "crf = sklearn_crfsuite.CRF(\n",
    "    algorithm='lbfgs',\n",
    "    c1=0.01,\n",
    "    c2=0.01,\n",
    "    max_iterations=100,\n",
    "    all_possible_transitions=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b95cf770",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install -U 'scikit-learn<0.24'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a8d3b924",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CRF(algorithm='lbfgs', all_possible_transitions=True, c1=0.01, c2=0.01,\n",
       "    keep_tempfiles=None, max_iterations=100)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "crf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f7f2f9f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           O       0.95      0.97      0.96     21068\n",
      "     problem       0.84      0.81      0.82      3367\n",
      "        test       0.83      0.79      0.81      1584\n",
      "   treatment       0.86      0.79      0.83      1578\n",
      "\n",
      "    accuracy                           0.93     27597\n",
      "   macro avg       0.87      0.84      0.85     27597\n",
      "weighted avg       0.93      0.93      0.93     27597\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = crf.predict(X_test)\n",
    "print(metrics.flat_classification_report(y_test, y_pred, labels = new_classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53b36dd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_transitions(trans_features):\n",
    "    for (label_from, label_to), weight in trans_features:\n",
    "        print(\"%-6s -> %-7s %0.6f\" % (label_from, label_to, weight))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "734182c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C1: 0.01 C2 0.01\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           O       0.95      0.97      0.96     21068\n",
      "     problem       0.84      0.81      0.82      3367\n",
      "        test       0.83      0.79      0.81      1584\n",
      "   treatment       0.86      0.79      0.83      1578\n",
      "\n",
      "    accuracy                           0.93     27597\n",
      "   macro avg       0.87      0.84      0.85     27597\n",
      "weighted avg       0.93      0.93      0.93     27597\n",
      "\n",
      "C1: 0.01 C2 0.05\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           O       0.95      0.97      0.96     21068\n",
      "     problem       0.83      0.81      0.82      3367\n",
      "        test       0.83      0.79      0.81      1584\n",
      "   treatment       0.88      0.79      0.83      1578\n",
      "\n",
      "    accuracy                           0.93     27597\n",
      "   macro avg       0.88      0.84      0.86     27597\n",
      "weighted avg       0.93      0.93      0.93     27597\n",
      "\n",
      "C1: 0.01 C2 0.1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           O       0.95      0.97      0.96     21068\n",
      "     problem       0.83      0.82      0.82      3367\n",
      "        test       0.84      0.80      0.82      1584\n",
      "   treatment       0.88      0.80      0.84      1578\n",
      "\n",
      "    accuracy                           0.93     27597\n",
      "   macro avg       0.88      0.85      0.86     27597\n",
      "weighted avg       0.93      0.93      0.93     27597\n",
      "\n",
      "C1: 0.01 C2 0.25\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           O       0.95      0.97      0.96     21068\n",
      "     problem       0.83      0.81      0.82      3367\n",
      "        test       0.85      0.80      0.83      1584\n",
      "   treatment       0.88      0.79      0.83      1578\n",
      "\n",
      "    accuracy                           0.93     27597\n",
      "   macro avg       0.88      0.84      0.86     27597\n",
      "weighted avg       0.93      0.93      0.93     27597\n",
      "\n",
      "C1: 0.01 C2 0.5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           O       0.95      0.97      0.96     21068\n",
      "     problem       0.83      0.81      0.82      3367\n",
      "        test       0.85      0.80      0.82      1584\n",
      "   treatment       0.88      0.78      0.83      1578\n",
      "\n",
      "    accuracy                           0.93     27597\n",
      "   macro avg       0.88      0.84      0.86     27597\n",
      "weighted avg       0.93      0.93      0.93     27597\n",
      "\n",
      "C1: 0.05 C2 0.01\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           O       0.95      0.97      0.96     21068\n",
      "     problem       0.84      0.81      0.83      3367\n",
      "        test       0.84      0.79      0.81      1584\n",
      "   treatment       0.88      0.80      0.84      1578\n",
      "\n",
      "    accuracy                           0.93     27597\n",
      "   macro avg       0.88      0.84      0.86     27597\n",
      "weighted avg       0.93      0.93      0.93     27597\n",
      "\n",
      "C1: 0.05 C2 0.05\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           O       0.95      0.97      0.96     21068\n",
      "     problem       0.84      0.81      0.83      3367\n",
      "        test       0.84      0.80      0.82      1584\n",
      "   treatment       0.87      0.80      0.83      1578\n",
      "\n",
      "    accuracy                           0.93     27597\n",
      "   macro avg       0.88      0.85      0.86     27597\n",
      "weighted avg       0.93      0.93      0.93     27597\n",
      "\n",
      "C1: 0.05 C2 0.1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           O       0.95      0.97      0.96     21068\n",
      "     problem       0.84      0.82      0.83      3367\n",
      "        test       0.84      0.80      0.82      1584\n",
      "   treatment       0.88      0.79      0.83      1578\n",
      "\n",
      "    accuracy                           0.93     27597\n",
      "   macro avg       0.88      0.84      0.86     27597\n",
      "weighted avg       0.93      0.93      0.93     27597\n",
      "\n",
      "C1: 0.05 C2 0.25\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           O       0.95      0.97      0.96     21068\n",
      "     problem       0.83      0.81      0.82      3367\n",
      "        test       0.86      0.79      0.82      1584\n",
      "   treatment       0.88      0.78      0.83      1578\n",
      "\n",
      "    accuracy                           0.93     27597\n",
      "   macro avg       0.88      0.84      0.86     27597\n",
      "weighted avg       0.93      0.93      0.93     27597\n",
      "\n",
      "C1: 0.05 C2 0.5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           O       0.95      0.97      0.96     21068\n",
      "     problem       0.83      0.82      0.82      3367\n",
      "        test       0.86      0.79      0.83      1584\n",
      "   treatment       0.89      0.78      0.83      1578\n",
      "\n",
      "    accuracy                           0.93     27597\n",
      "   macro avg       0.88      0.84      0.86     27597\n",
      "weighted avg       0.93      0.93      0.93     27597\n",
      "\n",
      "C1: 0.1 C2 0.01\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           O       0.96      0.97      0.96     21068\n",
      "     problem       0.84      0.82      0.83      3367\n",
      "        test       0.83      0.81      0.82      1584\n",
      "   treatment       0.87      0.81      0.84      1578\n",
      "\n",
      "    accuracy                           0.93     27597\n",
      "   macro avg       0.88      0.85      0.86     27597\n",
      "weighted avg       0.93      0.93      0.93     27597\n",
      "\n",
      "C1: 0.1 C2 0.05\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           O       0.95      0.97      0.96     21068\n",
      "     problem       0.85      0.82      0.83      3367\n",
      "        test       0.83      0.81      0.82      1584\n",
      "   treatment       0.87      0.80      0.84      1578\n",
      "\n",
      "    accuracy                           0.93     27597\n",
      "   macro avg       0.88      0.85      0.86     27597\n",
      "weighted avg       0.93      0.93      0.93     27597\n",
      "\n",
      "C1: 0.1 C2 0.1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           O       0.95      0.97      0.96     21068\n",
      "     problem       0.84      0.82      0.83      3367\n",
      "        test       0.84      0.80      0.82      1584\n",
      "   treatment       0.88      0.80      0.84      1578\n",
      "\n",
      "    accuracy                           0.93     27597\n",
      "   macro avg       0.88      0.85      0.86     27597\n",
      "weighted avg       0.93      0.93      0.93     27597\n",
      "\n",
      "C1: 0.1 C2 0.25\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           O       0.95      0.97      0.96     21068\n",
      "     problem       0.83      0.81      0.82      3367\n",
      "        test       0.85      0.80      0.82      1584\n",
      "   treatment       0.88      0.78      0.83      1578\n",
      "\n",
      "    accuracy                           0.93     27597\n",
      "   macro avg       0.88      0.84      0.86     27597\n",
      "weighted avg       0.93      0.93      0.93     27597\n",
      "\n",
      "C1: 0.1 C2 0.5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           O       0.95      0.97      0.96     21068\n",
      "     problem       0.83      0.81      0.82      3367\n",
      "        test       0.85      0.80      0.82      1584\n",
      "   treatment       0.89      0.78      0.83      1578\n",
      "\n",
      "    accuracy                           0.93     27597\n",
      "   macro avg       0.88      0.84      0.86     27597\n",
      "weighted avg       0.93      0.93      0.93     27597\n",
      "\n",
      "C1: 0.25 C2 0.01\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           O       0.96      0.97      0.96     21068\n",
      "     problem       0.83      0.82      0.83      3367\n",
      "        test       0.84      0.80      0.82      1584\n",
      "   treatment       0.87      0.80      0.83      1578\n",
      "\n",
      "    accuracy                           0.93     27597\n",
      "   macro avg       0.87      0.85      0.86     27597\n",
      "weighted avg       0.93      0.93      0.93     27597\n",
      "\n",
      "C1: 0.25 C2 0.05\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           O       0.95      0.97      0.96     21068\n",
      "     problem       0.85      0.82      0.83      3367\n",
      "        test       0.84      0.79      0.82      1584\n",
      "   treatment       0.88      0.79      0.83      1578\n",
      "\n",
      "    accuracy                           0.93     27597\n",
      "   macro avg       0.88      0.84      0.86     27597\n",
      "weighted avg       0.93      0.93      0.93     27597\n",
      "\n",
      "C1: 0.25 C2 0.1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           O       0.95      0.97      0.96     21068\n",
      "     problem       0.83      0.82      0.83      3367\n",
      "        test       0.84      0.80      0.82      1584\n",
      "   treatment       0.88      0.78      0.83      1578\n",
      "\n",
      "    accuracy                           0.93     27597\n",
      "   macro avg       0.88      0.84      0.86     27597\n",
      "weighted avg       0.93      0.93      0.93     27597\n",
      "\n",
      "C1: 0.25 C2 0.25\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           O       0.95      0.97      0.96     21068\n",
      "     problem       0.84      0.81      0.82      3367\n",
      "        test       0.87      0.79      0.83      1584\n",
      "   treatment       0.88      0.78      0.83      1578\n",
      "\n",
      "    accuracy                           0.93     27597\n",
      "   macro avg       0.88      0.84      0.86     27597\n",
      "weighted avg       0.93      0.93      0.93     27597\n",
      "\n",
      "C1: 0.25 C2 0.5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           O       0.95      0.97      0.96     21068\n",
      "     problem       0.83      0.81      0.82      3367\n",
      "        test       0.86      0.80      0.83      1584\n",
      "   treatment       0.88      0.77      0.82      1578\n",
      "\n",
      "    accuracy                           0.93     27597\n",
      "   macro avg       0.88      0.84      0.86     27597\n",
      "weighted avg       0.93      0.93      0.93     27597\n",
      "\n",
      "C1: 0.5 C2 0.01\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           O       0.95      0.96      0.96     21068\n",
      "     problem       0.81      0.81      0.81      3367\n",
      "        test       0.84      0.80      0.82      1584\n",
      "   treatment       0.87      0.79      0.83      1578\n",
      "\n",
      "    accuracy                           0.93     27597\n",
      "   macro avg       0.87      0.84      0.86     27597\n",
      "weighted avg       0.93      0.93      0.93     27597\n",
      "\n",
      "C1: 0.5 C2 0.05\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           O       0.95      0.96      0.96     21068\n",
      "     problem       0.82      0.81      0.82      3367\n",
      "        test       0.85      0.80      0.82      1584\n",
      "   treatment       0.87      0.78      0.82      1578\n",
      "\n",
      "    accuracy                           0.93     27597\n",
      "   macro avg       0.87      0.84      0.86     27597\n",
      "weighted avg       0.93      0.93      0.93     27597\n",
      "\n",
      "C1: 0.5 C2 0.1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           O       0.95      0.97      0.96     21068\n",
      "     problem       0.83      0.81      0.82      3367\n",
      "        test       0.85      0.80      0.82      1584\n",
      "   treatment       0.86      0.78      0.82      1578\n",
      "\n",
      "    accuracy                           0.93     27597\n",
      "   macro avg       0.87      0.84      0.86     27597\n",
      "weighted avg       0.93      0.93      0.93     27597\n",
      "\n",
      "C1: 0.5 C2 0.25\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           O       0.95      0.97      0.96     21068\n",
      "     problem       0.83      0.81      0.82      3367\n",
      "        test       0.86      0.79      0.82      1584\n",
      "   treatment       0.87      0.77      0.82      1578\n",
      "\n",
      "    accuracy                           0.93     27597\n",
      "   macro avg       0.88      0.83      0.85     27597\n",
      "weighted avg       0.93      0.93      0.93     27597\n",
      "\n",
      "C1: 0.5 C2 0.5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           O       0.95      0.97      0.96     21068\n",
      "     problem       0.83      0.80      0.81      3367\n",
      "        test       0.86      0.79      0.83      1584\n",
      "   treatment       0.87      0.76      0.81      1578\n",
      "\n",
      "    accuracy                           0.93     27597\n",
      "   macro avg       0.88      0.83      0.85     27597\n",
      "weighted avg       0.92      0.93      0.92     27597\n",
      "\n"
     ]
    }
   ],
   "source": [
    "c_1 = [0.01, 0.05, 0.1, 0.25, 0.5]\n",
    "c_2 = [0.01, 0.05, 0.1, 0.25, 0.5]\n",
    "\n",
    "for i in range(len(c_1)):\n",
    "    for j in range(len(c_2)):\n",
    "        crf = sklearn_crfsuite.CRF(\n",
    "            algorithm='lbfgs',\n",
    "            c1=c_1[i],\n",
    "            c2=c_2[j],\n",
    "            max_iterations=100,\n",
    "            all_possible_transitions=True\n",
    "            )\n",
    "        crf.fit(X_train, y_train)\n",
    "        y_pred = crf.predict(X_test)\n",
    "        print(\"C1:\", c_1[i], \"C2\", c_2[j])\n",
    "        print(metrics.flat_classification_report(y_test, y_pred, labels = new_classes))\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
