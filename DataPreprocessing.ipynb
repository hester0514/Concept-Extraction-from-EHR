{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1d3d387b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob  # Finds all the pathnames matching a specified pattern, \n",
    "             # typically specified with regex (re) \n",
    "import re\n",
    "import pandas as pd\n",
    "from nltk import pos_tag\n",
    "from nltk.chunk.regexp import RegexpChunkParser, ChunkRule, RegexpParser\n",
    "from nltk.tree import Tree\n",
    "import numpy as np\n",
    "import os.path \n",
    "from nltk import tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a8f25fd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = 'train_data/beth/'  # Path to directory containing .con and .txt files\n",
    "output_dir = data_dir + 'output/'\n",
    "\n",
    "a_corpus = glob.glob(data_dir+'concept/*.con')  # Make list of concept files\n",
    "e_corpus = glob.glob(data_dir+'txt/*.txt')  # Make list of documents\n",
    "\n",
    "base_str = \"record-\"\n",
    "# base_str = ['_DH', '_ELMVH', '_WGH', '_PUMC', '_RWH', '_SC', '_a', '_EH', \n",
    "#            '_YC','']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "94bcafc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count of concept files with corresponding doc: 73\n"
     ]
    }
   ],
   "source": [
    "a_ids = []\n",
    "e_ids = []\n",
    "\n",
    "# Use regex to create doc id \n",
    "\n",
    "for con in a_corpus:\n",
    "    f_id = re.findall(r'\\d+', con)[0]\n",
    "    a_ids.append(f_id)\n",
    "\n",
    "for doc in e_corpus:\n",
    "    f_id = re.findall(r'\\d+', doc)[0]\n",
    "    e_ids.append(f_id)\n",
    "\n",
    "a_ids = tuple(sorted(a_ids)) \n",
    "e_ids = tuple(sorted(e_ids))\n",
    "intersection = list(set(a_ids) & set(e_ids))\n",
    "if len(intersection) == len(a_ids):\n",
    "    print(\"Count of concept files with corresponding doc:\", len(intersection))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "04b8f04e",
   "metadata": {},
   "outputs": [],
   "source": [
    "a_corpus = []\n",
    "e_corpus = []\n",
    "\n",
    "# for f_id in a_ids:\n",
    "#     for i in base_str:\n",
    "#         path = data_dir + \"concept/\" + f_id + i +\".con\"\n",
    "#         if os.path.isfile(path) == True:\n",
    "#             with open(path) as f:\n",
    "#                 content = f.read().splitlines()\n",
    "#                 a_corpus.append(content)\n",
    "\n",
    "#         path = data_dir + \"txt/\" + f_id + i +\".txt\"\n",
    "#         if os.path.isfile(path) == True:\n",
    "#             with open(path) as f:\n",
    "#                 content = f.read().splitlines()\n",
    "#                 e_corpus.append(content)\n",
    "\n",
    "for f_id in a_ids:\n",
    "    path = data_dir + \"concept/\" + base_str + f_id +\".con\"\n",
    "    with open(path) as f:\n",
    "        content = f.read().splitlines()\n",
    "        a_corpus.append(content)\n",
    "\n",
    "    path = data_dir + \"txt/\" + base_str + f_id +\".txt\"\n",
    "    with open(path) as f:\n",
    "        content = f.read().splitlines()\n",
    "        e_corpus.append(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "94c7ef08",
   "metadata": {},
   "outputs": [],
   "source": [
    "entries_cols = [\"id\", \"row\", \"offset\", \"word\"]\n",
    "entries_df = pd.DataFrame(columns=entries_cols)\n",
    "\n",
    "annotations_cols = [\"id\", \"NER_tag\", \"row\", \"offset\", \"length\"]\n",
    "annotations_df = pd.DataFrame(columns=annotations_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ec7dfdc6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>NER_tag</th>\n",
       "      <th>row</th>\n",
       "      <th>offset</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>105</td>\n",
       "      <td>problem</td>\n",
       "      <td>55</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>105</td>\n",
       "      <td>problem</td>\n",
       "      <td>55</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>105</td>\n",
       "      <td>problem</td>\n",
       "      <td>55</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>105</td>\n",
       "      <td>problem</td>\n",
       "      <td>143</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>105</td>\n",
       "      <td>problem</td>\n",
       "      <td>143</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>105</td>\n",
       "      <td>problem</td>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>105</td>\n",
       "      <td>problem</td>\n",
       "      <td>68</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>105</td>\n",
       "      <td>problem</td>\n",
       "      <td>68</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>105</td>\n",
       "      <td>problem</td>\n",
       "      <td>68</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>105</td>\n",
       "      <td>test</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>105</td>\n",
       "      <td>problem</td>\n",
       "      <td>21</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>105</td>\n",
       "      <td>problem</td>\n",
       "      <td>21</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>105</td>\n",
       "      <td>problem</td>\n",
       "      <td>21</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>105</td>\n",
       "      <td>problem</td>\n",
       "      <td>54</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>105</td>\n",
       "      <td>problem</td>\n",
       "      <td>54</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>105</td>\n",
       "      <td>test</td>\n",
       "      <td>20</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>105</td>\n",
       "      <td>problem</td>\n",
       "      <td>18</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>105</td>\n",
       "      <td>problem</td>\n",
       "      <td>18</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>105</td>\n",
       "      <td>treatment</td>\n",
       "      <td>51</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>105</td>\n",
       "      <td>treatment</td>\n",
       "      <td>51</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>105</td>\n",
       "      <td>treatment</td>\n",
       "      <td>51</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>105</td>\n",
       "      <td>treatment</td>\n",
       "      <td>143</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>105</td>\n",
       "      <td>treatment</td>\n",
       "      <td>143</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>105</td>\n",
       "      <td>treatment</td>\n",
       "      <td>143</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>105</td>\n",
       "      <td>problem</td>\n",
       "      <td>143</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>105</td>\n",
       "      <td>problem</td>\n",
       "      <td>14</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>105</td>\n",
       "      <td>problem</td>\n",
       "      <td>14</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>105</td>\n",
       "      <td>problem</td>\n",
       "      <td>14</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>105</td>\n",
       "      <td>test</td>\n",
       "      <td>45</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>105</td>\n",
       "      <td>test</td>\n",
       "      <td>19</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>105</td>\n",
       "      <td>problem</td>\n",
       "      <td>19</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>105</td>\n",
       "      <td>problem</td>\n",
       "      <td>19</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>105</td>\n",
       "      <td>treatment</td>\n",
       "      <td>103</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>105</td>\n",
       "      <td>test</td>\n",
       "      <td>47</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>105</td>\n",
       "      <td>test</td>\n",
       "      <td>47</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>105</td>\n",
       "      <td>test</td>\n",
       "      <td>47</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>105</td>\n",
       "      <td>problem</td>\n",
       "      <td>98</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>105</td>\n",
       "      <td>treatment</td>\n",
       "      <td>52</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>105</td>\n",
       "      <td>treatment</td>\n",
       "      <td>52</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>105</td>\n",
       "      <td>treatment</td>\n",
       "      <td>52</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>105</td>\n",
       "      <td>treatment</td>\n",
       "      <td>52</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>105</td>\n",
       "      <td>treatment</td>\n",
       "      <td>52</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>105</td>\n",
       "      <td>treatment</td>\n",
       "      <td>52</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>105</td>\n",
       "      <td>test</td>\n",
       "      <td>19</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>105</td>\n",
       "      <td>test</td>\n",
       "      <td>19</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>105</td>\n",
       "      <td>test</td>\n",
       "      <td>43</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>105</td>\n",
       "      <td>treatment</td>\n",
       "      <td>133</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>105</td>\n",
       "      <td>treatment</td>\n",
       "      <td>16</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>105</td>\n",
       "      <td>treatment</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>105</td>\n",
       "      <td>treatment</td>\n",
       "      <td>16</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     id    NER_tag  row  offset\n",
       "0   105    problem   55       6\n",
       "1   105    problem   55       7\n",
       "2   105    problem   55       8\n",
       "3   105    problem  143       1\n",
       "4   105    problem  143       2\n",
       "5   105    problem   26       0\n",
       "6   105    problem   68       1\n",
       "7   105    problem   68       2\n",
       "8   105    problem   68       3\n",
       "9   105       test   21       0\n",
       "10  105    problem   21       6\n",
       "11  105    problem   21       7\n",
       "12  105    problem   21       8\n",
       "13  105    problem   54       2\n",
       "14  105    problem   54       3\n",
       "15  105       test   20      12\n",
       "16  105    problem   18       5\n",
       "17  105    problem   18       6\n",
       "18  105  treatment   51       2\n",
       "19  105  treatment   51       3\n",
       "20  105  treatment   51       4\n",
       "21  105  treatment  143       6\n",
       "22  105  treatment  143       7\n",
       "23  105  treatment  143       8\n",
       "24  105    problem  143       0\n",
       "25  105    problem   14       2\n",
       "26  105    problem   14       3\n",
       "27  105    problem   14       4\n",
       "28  105       test   45       0\n",
       "29  105       test   19       9\n",
       "30  105    problem   19      12\n",
       "31  105    problem   19      13\n",
       "32  105  treatment  103       9\n",
       "33  105       test   47       0\n",
       "34  105       test   47       1\n",
       "35  105       test   47       2\n",
       "36  105    problem   98       3\n",
       "37  105  treatment   52      11\n",
       "38  105  treatment   52      12\n",
       "39  105  treatment   52      13\n",
       "40  105  treatment   52      14\n",
       "41  105  treatment   52      15\n",
       "42  105  treatment   52      16\n",
       "43  105       test   19       6\n",
       "44  105       test   19       7\n",
       "45  105       test   43       0\n",
       "46  105  treatment  133       1\n",
       "47  105  treatment   16      15\n",
       "48  105  treatment   16      16\n",
       "49  105  treatment   16      17"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "annotations_df = pd.DataFrame(columns=annotations_cols)  # Reset df\n",
    "tmp_list = []  # Set up variable to hold row info\n",
    "\n",
    "for i, document in enumerate(a_corpus):\n",
    "    \n",
    "    for row in document:\n",
    "        row = row.split(\"||\")\n",
    "        text_info = row[0]\n",
    "        type_info = row[1]\n",
    "        \n",
    "        text = text_info.split('\"')[1]\n",
    "        \n",
    "        offset_start = text_info.split(' ')[-2]\n",
    "        offset_end = text_info.split(' ')[-1]\n",
    "        \n",
    "        line = offset_start.split(':')[0] # Given one sentence to line, \n",
    "                                          # line number will be the same for offset_start and offset_end\n",
    "        \n",
    "        word_offset_start = int(offset_start.split(':')[1])\n",
    "        word_offset_end = int(offset_end.split(':')[1])\n",
    "        length = word_offset_end-word_offset_start +1\n",
    "        \n",
    "        a_type = type_info.split('\"')[-2]\n",
    "        \n",
    "        # Split text into tokens with IOB tags\n",
    "        first = True  # Set up flag to id start of text\n",
    "#         BIO_tag = \"B-\"\n",
    "        if length > 1:  # Isolate text with multiple tokens \n",
    "            for offset in range(word_offset_start, word_offset_end+1):\n",
    "                if first:\n",
    "                    tag_label = a_type # Set tag for first word to start with B-\n",
    "                    first = False  # Change flag\n",
    "                else:\n",
    "                    tag_label = tag_label\n",
    "                tmp_list.append([a_ids[i], tag_label, line, offset, 1])                \n",
    "        else:\n",
    "            tmp_list.append([a_ids[i], a_type, line, word_offset_start, length])\n",
    "        \n",
    "annotations_df = pd.DataFrame(tmp_list, columns=annotations_cols)\n",
    "annotations_df = annotations_df.drop(columns=[\"length\"])\n",
    "\n",
    "annotations_df.head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2e216a66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>NER_tag</th>\n",
       "      <th>row</th>\n",
       "      <th>offset</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>105</td>\n",
       "      <td>problem</td>\n",
       "      <td>55</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>105</td>\n",
       "      <td>problem</td>\n",
       "      <td>55</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>105</td>\n",
       "      <td>problem</td>\n",
       "      <td>55</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>105</td>\n",
       "      <td>problem</td>\n",
       "      <td>143</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>105</td>\n",
       "      <td>problem</td>\n",
       "      <td>143</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>105</td>\n",
       "      <td>problem</td>\n",
       "      <td>56</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>105</td>\n",
       "      <td>problem</td>\n",
       "      <td>56</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>105</td>\n",
       "      <td>problem</td>\n",
       "      <td>89</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>105</td>\n",
       "      <td>problem</td>\n",
       "      <td>89</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>105</td>\n",
       "      <td>problem</td>\n",
       "      <td>89</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     id  NER_tag  row  offset\n",
       "0   105  problem   55       6\n",
       "1   105  problem   55       7\n",
       "2   105  problem   55       8\n",
       "3   105  problem  143       1\n",
       "4   105  problem  143       2\n",
       "..  ...      ...  ...     ...\n",
       "95  105  problem   56       1\n",
       "96  105  problem   56       2\n",
       "97  105  problem   89       3\n",
       "98  105  problem   89       4\n",
       "99  105  problem   89       5\n",
       "\n",
       "[100 rows x 4 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "annotations_df.head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6d8b20a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 named entities\n"
     ]
    }
   ],
   "source": [
    "entries_df = pd.DataFrame(columns=entries_cols)  # Reset df\n",
    "tmp_list = []\n",
    "\n",
    "for doc_i, document in enumerate(e_corpus):\n",
    "    \n",
    "    tmp_list.append([0, 0, 0, \"-DOCSTART-\"])\n",
    "    tmp_list.append([0, 0, 0, \"-EMPTYLINE-\"])\n",
    "    \n",
    "    for row_i, row in enumerate(document):\n",
    "        row_split = row.split(\" \")\n",
    "        for word_i, word in enumerate(row_split):\n",
    "            word = word.replace(\"\\t\", \"\")\n",
    "            word_id = a_ids[doc_i]\n",
    "            word_row = row_i+1  # 1-based indexing \n",
    "            word_offset = word_i # 0-based indexing\n",
    "            \n",
    "            if len(word) > 0 and \"|\" not in word:\n",
    "                tmp_list.append([word_id, word_row, word_offset, word])\n",
    "        \n",
    "    tmp_list.append([0, 0, 0, \"-EMPTYLINE-\"])\n",
    "\n",
    "entries_df = pd.DataFrame(tmp_list, columns=entries_cols)\n",
    "\n",
    "ner_counter = [1 for i in annotations_df[\"NER_tag\"] if \"B-\" in i]\n",
    "print(len(ner_counter), \"named entities\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0d986272",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns with missing data:\n",
      " id         False\n",
      "row        False\n",
      "offset     False\n",
      "word       False\n",
      "NER_tag     True\n",
      "dtype: bool\n"
     ]
    }
   ],
   "source": [
    "annotations_df[['id', 'row', 'offset']] = annotations_df[['id', 'row', 'offset']].apply(pd.to_numeric)\n",
    "annotations_df['NER_tag'] = annotations_df[\"NER_tag\"].astype(str)\n",
    "entries_df[['id', 'row', 'offset']] = entries_df[['id', 'row', 'offset']].apply(pd.to_numeric)\n",
    "entries_df[\"word\"] = entries_df[\"word\"].astype(str)\n",
    "\n",
    "result_df = pd.merge(entries_df, annotations_df, how=\"left\", on=['id', 'row', 'offset'])\n",
    "\n",
    "# Check for NaNs (should be only in NER_tag, where NaNs will be replaced with \"O\" (outside))\n",
    "print(\"Columns with missing data:\\n\", result_df.isna().any())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0dd90964",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 named entities and 88942 tokens\n"
     ]
    }
   ],
   "source": [
    "result_df = result_df.fillna(\"O\")\n",
    "result_df = result_df.drop(columns=[\"id\", \"row\", \"offset\"])\n",
    "\n",
    "ner_counter = [1 for i in result_df[\"NER_tag\"] if \"B-\" in i]\n",
    "print(len(ner_counter), \"named entities and\", result_df.shape[0], \"tokens\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "320e5ed7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /Users/Sylvia/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('averaged_perceptron_tagger')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dc001ff8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "88942 tokens\n"
     ]
    }
   ],
   "source": [
    "text = result_df[\"word\"].tolist()\n",
    "text_pos = pos_tag(text)\n",
    "text_pos_list = [i[1] for i in text_pos]\n",
    "print(len(text_pos_list), 'tokens')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4f400c96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rule_0 = ChunkRule(\"<DT>?<JJ.*>*<NN.*>+\", \"More complete chunk NP sequences\")\n",
    "chunk_parser_np = RegexpChunkParser([rule_0],chunk_label='NP')\n",
    "chunk_result_tree_np = chunk_parser_np.parse(text_pos)\n",
    "\n",
    "chunk_tag_np = []\n",
    "\n",
    "for i in chunk_result_tree_np:\n",
    "    if isinstance(i, Tree):\n",
    "        for j in range(0, len(i)):\n",
    "            if j == 0:\n",
    "                # print(\"B-\" + i.label())\n",
    "                chunk_tag_np.append(\"B-\" + i.label())\n",
    "            else:\n",
    "                chunk_tag_np.append(\"I-\" + i.label())\n",
    "                # print(\"I-\" + i.label())\n",
    "    else:\n",
    "        # print(\"O\")\n",
    "        chunk_tag_np.append(\"O\")\n",
    "\n",
    "len(chunk_tag_np) == result_df.shape[0]  # check that chunk col has same length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0ec59be5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rule_1 = ChunkRule(\"<VBD|IN|\\.>\", \"Verb phrases\")\n",
    "chunk_parser_vp = RegexpChunkParser([rule_1],chunk_label='VP')\n",
    "chunk_result_tree_vp = chunk_parser_vp.parse(text_pos)\n",
    "\n",
    "chunk_tag_vp = []\n",
    "\n",
    "for i in chunk_result_tree_vp:\n",
    "    if isinstance(i, Tree):\n",
    "        for j in range(0, len(i)):\n",
    "            if j == 0:\n",
    "                # print(\"B-\" + i.label())\n",
    "                chunk_tag_vp.append(\"B-\" + i.label())\n",
    "            else:\n",
    "                chunk_tag_vp.append(\"I-\" + i.label())\n",
    "                # print(\"I-\" + i.label())\n",
    "    else:\n",
    "        # print(\"O\")\n",
    "        chunk_tag_vp.append(\"O\")\n",
    "        \n",
    "len(chunk_tag_np) == result_df.shape[0] == len(chunk_tag_vp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "13a0c4c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, entry in enumerate(chunk_tag_np):\n",
    "    if entry == \"O\":\n",
    "        chunk_tag_np[i] = chunk_tag_vp[i]\n",
    "        \n",
    "result_df[\"POS_tag\"] = text_pos_list\n",
    "result_df[\"chunk_tag\"] = chunk_tag_np\n",
    "\n",
    "result_df = result_df[['word', 'POS_tag', 'chunk_tag', 'NER_tag']]  # Reorder columns\n",
    "result_df[['word', 'POS_tag', 'chunk_tag', 'NER_tag']] = result_df[['word', 'POS_tag', 'chunk_tag', 'NER_tag']].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5e560d73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4585 total sentences\n"
     ]
    }
   ],
   "source": [
    "output_df = result_df.copy()\n",
    "\n",
    "# Identify idx at end of sentences\n",
    "idx = output_df[output_df['word'] == '.'].index.values.tolist()\n",
    "print(len(idx), 'total sentences')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "794c84ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>POS_tag</th>\n",
       "      <th>chunk_tag</th>\n",
       "      <th>NER_tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    word POS_tag chunk_tag NER_tag\n",
       "92                                \n",
       "108                               \n",
       "130                               \n",
       "148                               \n",
       "155                               "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_new = pd.DataFrame(index=[el+0.5 for el in idx]) \n",
    "output_df = pd.concat([output_df, df_new])\n",
    "output_df = output_df.sort_index()\n",
    "output_df = output_df.reset_index(drop=True)\n",
    "output_df.fillna(\"\", inplace=True)\n",
    "output_df[output_df['word'] == \"\"].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b721e7dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages/pandas/core/indexing.py:1732: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_block(indexer, value, name)\n"
     ]
    }
   ],
   "source": [
    "output_df['Sentences #'] = (output_df['word'] == \".\").cumsum() + 1\n",
    "output_df['Sentences #'] = output_df['Sentences #'].shift(1)\n",
    "output_df['Sentences #'].iloc[0] = 1\n",
    "output_df['Sentences #'] = output_df['Sentences #'].astype(int)\n",
    "output_df['Sentences #'] = 'Sentence:' + output_df['Sentences #'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2be28eac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>POS_tag</th>\n",
       "      <th>chunk_tag</th>\n",
       "      <th>NER_tag</th>\n",
       "      <th>Sentences #</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-DOCSTART-</td>\n",
       "      <td>JJ</td>\n",
       "      <td>B-NP</td>\n",
       "      <td>O</td>\n",
       "      <td>Sentence:1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-EMPTYLINE-</td>\n",
       "      <td>NNP</td>\n",
       "      <td>I-NP</td>\n",
       "      <td>O</td>\n",
       "      <td>Sentence:1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Admission</td>\n",
       "      <td>NNP</td>\n",
       "      <td>I-NP</td>\n",
       "      <td>O</td>\n",
       "      <td>Sentence:1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Date</td>\n",
       "      <td>NNP</td>\n",
       "      <td>I-NP</td>\n",
       "      <td>O</td>\n",
       "      <td>Sentence:1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>:</td>\n",
       "      <td>:</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>Sentence:1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93522</th>\n",
       "      <td>End</td>\n",
       "      <td>NNP</td>\n",
       "      <td>B-NP</td>\n",
       "      <td>O</td>\n",
       "      <td>Sentence:4586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93523</th>\n",
       "      <td>of</td>\n",
       "      <td>IN</td>\n",
       "      <td>B-VP</td>\n",
       "      <td>O</td>\n",
       "      <td>Sentence:4586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93524</th>\n",
       "      <td>Report</td>\n",
       "      <td>NNP</td>\n",
       "      <td>B-NP</td>\n",
       "      <td>O</td>\n",
       "      <td>Sentence:4586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93525</th>\n",
       "      <td>)</td>\n",
       "      <td>)</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>Sentence:4586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93526</th>\n",
       "      <td>-EMPTYLINE-</td>\n",
       "      <td>VBP</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>Sentence:4586</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>93527 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              word POS_tag chunk_tag NER_tag    Sentences #\n",
       "0       -DOCSTART-      JJ      B-NP       O     Sentence:1\n",
       "1      -EMPTYLINE-     NNP      I-NP       O     Sentence:1\n",
       "2        Admission     NNP      I-NP       O     Sentence:1\n",
       "3             Date     NNP      I-NP       O     Sentence:1\n",
       "4                :       :         O       O     Sentence:1\n",
       "...            ...     ...       ...     ...            ...\n",
       "93522          End     NNP      B-NP       O  Sentence:4586\n",
       "93523           of      IN      B-VP       O  Sentence:4586\n",
       "93524       Report     NNP      B-NP       O  Sentence:4586\n",
       "93525            )       )         O       O  Sentence:4586\n",
       "93526  -EMPTYLINE-     VBP         O       O  Sentence:4586\n",
       "\n",
       "[93527 rows x 5 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "98f326aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt(output_dir+\"beth.txt\", output_df.values, fmt=\"%s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9c9a6240",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train = int(round(output_df.shape[0]*.7,0))  \n",
    "# dev = int(round(output_df.shape[0]*.85,0))\n",
    "# result_train_df = output_df.iloc[:train]\n",
    "# result_dev_df = output_df.iloc[train:dev]\n",
    "# result_test_df = output_df.iloc[dev:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7d86d01f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.savetxt(output_dir+\"train.txt\", result_train_df.values, fmt=\"%s\")\n",
    "# np.savetxt(output_dir+\"valid.txt\", result_dev_df.values, fmt=\"%s\")\n",
    "# np.savetxt(output_dir+\"test.txt\", result_test_df.values, fmt=\"%s\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
